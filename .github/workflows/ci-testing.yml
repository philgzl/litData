name: CI Testing

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on: # Trigger the workflow on push or pull request, but only for the main branch
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, reopened, ready_for_review, synchronize]

defaults:
  run:
    shell: bash

jobs:
  pytester:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-22.04", "macos-14", "windows-2022"]
        python-version: ["3.9", "3.10", "3.11", "3.12", "3.13"]
        exclude:
          - { os: "windows-2022", python-version: "3.13" }
          - { os: "macos-14", python-version: "3.12" }
          - { os: "macos-14", python-version: "3.13" }

    # Timeout: https://stackoverflow.com/a/59076067/4521646
    timeout-minutes: 60
    env:
      UV_TORCH_BACKEND: "cpu"

    steps:
      - uses: actions/checkout@v4
      - name: Install uv and setup python ${{ matrix.python-version }}
        uses: astral-sh/setup-uv@v6
        with:
          activate-environment: true
          python-version: ${{ matrix.python-version }}
          enable-cache: true

      - name: Install package & dependencies
        run: |
          uv pip install -U lightning-sdk
          uv pip install -e ".[extras]" -r requirements/test.txt -U -q
          uv pip list

      - name: Run fast tests in parallel
        run: |
          pytest \
            tests/streaming tests/utilities \
            tests/test_cli.py tests/test_debugger.py \
            -n 2 --cov=litdata --cov-append --cov-report= --durations=120

      - name: Run processing tests sequentially
        run: |
          pytest tests/processing tests/raw --cov=litdata --cov-append --cov-report= --durations=90

      - name: Statistics
        continue-on-error: true
        run: |
          coverage report
          coverage xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests,${{ matrix.os }},${{ matrix.python-version }}
          env_vars: OS,PYTHON
          name: codecov-umbrella
          fail_ci_if_error: false

  testing-guardian:
    runs-on: ubuntu-latest
    needs: pytester
    if: always()
    steps:
      - run: echo "${{ needs.pytester.result }}"
      - name: failing...
        if: needs.pytester.result == 'failure'
        run: exit 1
      - name: cancelled or skipped...
        if: contains(fromJSON('["cancelled", "skipped"]'), needs.pytester.result)
        timeout-minutes: 1
        run: sleep 90
